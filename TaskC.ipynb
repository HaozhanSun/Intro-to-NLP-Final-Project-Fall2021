{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "“Eng Task C - Ensemble DistilRoberta AttnMask Dropout.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [
        "0NOwcyecoupm",
        "EfXDJER9wnGn",
        "faAM7TdDoup5"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "547b3b1e7242417aa69b8b9f7816cfef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_264a7a8cfef84eaf8ded6de572dfe903",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac69e9fe1d9d422ca4f11bca8ecd1e0c",
              "IPY_MODEL_afc2c2874e5f4f0b8cf2a4cdfcc900bf",
              "IPY_MODEL_c2462834827c429394d4b8f6269673d0"
            ]
          }
        },
        "264a7a8cfef84eaf8ded6de572dfe903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac69e9fe1d9d422ca4f11bca8ecd1e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df5185c75df041b6be13e77b8e44b912",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c5b4bb4db32482f9940f8e486d081f6"
          }
        },
        "afc2c2874e5f4f0b8cf2a4cdfcc900bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6591e11f069a4f9fa409cd11a1e68804",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50d14a915b544bd595e256f1bdb33b27"
          }
        },
        "c2462834827c429394d4b8f6269673d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4a2cd2770004e048a991f0c80ef15c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 878k/878k [00:00&lt;00:00, 2.83MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d035b5186b34aed8b7b3de6d6e465a2"
          }
        },
        "df5185c75df041b6be13e77b8e44b912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c5b4bb4db32482f9940f8e486d081f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6591e11f069a4f9fa409cd11a1e68804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50d14a915b544bd595e256f1bdb33b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a2cd2770004e048a991f0c80ef15c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d035b5186b34aed8b7b3de6d6e465a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dde202facd44e15a11e960a1e72986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc41d8933fe248e293ea974366f368b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d70f421be0f4cf18520c883c3e391df",
              "IPY_MODEL_32fc3c792bf44b7599e72158dff780ea",
              "IPY_MODEL_b21e2c92a37f494fa3fae15edb0b19c1"
            ]
          }
        },
        "dc41d8933fe248e293ea974366f368b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d70f421be0f4cf18520c883c3e391df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fecb2cb53635447bb053d4baf166549c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b6f3c54149a476e9c66457b6efe5725"
          }
        },
        "32fc3c792bf44b7599e72158dff780ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a23f7f1c0e64b2799975ffeb06ca0f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c73f05ab90974b499082298251060e43"
          }
        },
        "b21e2c92a37f494fa3fae15edb0b19c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cc94df9ce894c21b581e8bdbd14f6f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 2.27MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e89e1794e8a4a50acaf71c746c49e3c"
          }
        },
        "fecb2cb53635447bb053d4baf166549c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b6f3c54149a476e9c66457b6efe5725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a23f7f1c0e64b2799975ffeb06ca0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c73f05ab90974b499082298251060e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cc94df9ce894c21b581e8bdbd14f6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e89e1794e8a4a50acaf71c746c49e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ef4cf827b98463f8b90a5da4f370536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d2a3a8cbb394904a97bd8105214df6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f4d34caf198402b9df9408631c8b112",
              "IPY_MODEL_a6de4b7709d3482780e1529b66034b9b",
              "IPY_MODEL_65d76e52afec473d830ec5222f247fc3"
            ]
          }
        },
        "0d2a3a8cbb394904a97bd8105214df6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f4d34caf198402b9df9408631c8b112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_761fff9acfb54e52811dd0bd3f9812f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3461e00be764f70b0115eb3d8ac5832"
          }
        },
        "a6de4b7709d3482780e1529b66034b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1ce5710a96c4b1b84580bb7a624ce8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76e3a77fcbc14070a6f9d7ba075fb69e"
          }
        },
        "65d76e52afec473d830ec5222f247fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37bf26f18078422fa49994d00a8ed292",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 1.53MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c5ee266fb9b4f22a75436f3d949bb5b"
          }
        },
        "761fff9acfb54e52811dd0bd3f9812f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3461e00be764f70b0115eb3d8ac5832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1ce5710a96c4b1b84580bb7a624ce8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76e3a77fcbc14070a6f9d7ba075fb69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37bf26f18078422fa49994d00a8ed292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c5ee266fb9b4f22a75436f3d949bb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24a041d4024d4661807592836a776f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0177a608bb834d9aa81e354f822bc1b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ab517d94bca4418aca8707b81c8fc3b",
              "IPY_MODEL_07aeda16928e4ac9a62af79a3a9e5927",
              "IPY_MODEL_872c2ae583584eea9e5c6fe74623cf04"
            ]
          }
        },
        "0177a608bb834d9aa81e354f822bc1b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ab517d94bca4418aca8707b81c8fc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5a2412342da41c4aa749fca49a7e924",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_274a625e202f4a48b9756c9f2c86fb6a"
          }
        },
        "07aeda16928e4ac9a62af79a3a9e5927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8845c1ca776d475c88b44cb75814191e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 480,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 480,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_208b28f930e94cfb8176d0271c59c722"
          }
        },
        "872c2ae583584eea9e5c6fe74623cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_514e7d7518a440148756605cb44e28f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480/480 [00:00&lt;00:00, 15.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10625350badf47e8a0187ebaf95a34a0"
          }
        },
        "c5a2412342da41c4aa749fca49a7e924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "274a625e202f4a48b9756c9f2c86fb6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8845c1ca776d475c88b44cb75814191e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "208b28f930e94cfb8176d0271c59c722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "514e7d7518a440148756605cb44e28f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10625350badf47e8a0187ebaf95a34a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3402debb209a4eea99ca4a06ff83cfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a6ee4d51a6b4eb5bd84bbb11efcd908",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e56b5d61e9494381967a0ae34f490247",
              "IPY_MODEL_94bba555c3ec431ab65f3cfa1789cf9c",
              "IPY_MODEL_7a0dd9dbe39d4f849cb411961c000c7c"
            ]
          }
        },
        "0a6ee4d51a6b4eb5bd84bbb11efcd908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e56b5d61e9494381967a0ae34f490247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1611203a8d5c4ec29f14030c48d4fcca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_979f47c68abf4bf8a36fa685bfd8105f"
          }
        },
        "94bba555c3ec431ab65f3cfa1789cf9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b516eeaee74483893962c297e103886",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 331070498,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 331070498,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_525dbeb604ad4cb8bd008c145482c20a"
          }
        },
        "7a0dd9dbe39d4f849cb411961c000c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f12a189174f74406ba581cb3e1b51649",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 316M/316M [00:07&lt;00:00, 46.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82d0d21d84bb457586849b3e90614280"
          }
        },
        "1611203a8d5c4ec29f14030c48d4fcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "979f47c68abf4bf8a36fa685bfd8105f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b516eeaee74483893962c297e103886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "525dbeb604ad4cb8bd008c145482c20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f12a189174f74406ba581cb3e1b51649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82d0d21d84bb457586849b3e90614280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2152d09dfa41445c843a19707180c7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63de84121fca4d859425fd852237212e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4abae12fb0947138e7b7ebd63dc52ff",
              "IPY_MODEL_20fc314407724eca9138bdb88d2f156d",
              "IPY_MODEL_4185483be77f4d23bf103aec4e25545b"
            ]
          }
        },
        "63de84121fca4d859425fd852237212e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4abae12fb0947138e7b7ebd63dc52ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0c727e9ba62439e9dc71c8e227ef759",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training_routine:  35%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_631df1a3c3754c2b8abe3b78f05c464a"
          }
        },
        "20fc314407724eca9138bdb88d2f156d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f69cefb2c504ea4911004829402992f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc706ccbfcd042578282591828e74db7"
          }
        },
        "4185483be77f4d23bf103aec4e25545b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f870bccaa2ca47b097bc6c828a7fb35f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7/20 [44:06&lt;1:21:49, 377.67s/it, best_f1=0.769, current=0.758]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66d73e1ef2824419980efa33a533adeb"
          }
        },
        "a0c727e9ba62439e9dc71c8e227ef759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "631df1a3c3754c2b8abe3b78f05c464a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f69cefb2c504ea4911004829402992f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc706ccbfcd042578282591828e74db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f870bccaa2ca47b097bc6c828a7fb35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66d73e1ef2824419980efa33a533adeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cf8dfed34c245548f29cc436a280b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69d4a1164c0f4f4282fdb42aa7576d3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f94b725bbb5d48e0a9fca900e4cfaa6b",
              "IPY_MODEL_018268f03cc6430389f3e36dc1286ce8",
              "IPY_MODEL_c5ce6820c5014d1595dbd52e633810f9"
            ]
          }
        },
        "69d4a1164c0f4f4282fdb42aa7576d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f94b725bbb5d48e0a9fca900e4cfaa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95c946abcee844508abb6032dac75c4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=train : ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01dd7ddf0b0b4ed094e4ff9d0a033f0b"
          }
        },
        "018268f03cc6430389f3e36dc1286ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be23546d86194c64998150e4cd3f3fd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 730,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 730,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7438c89d7a945e98743f034ede620a8"
          }
        },
        "c5ce6820c5014d1595dbd52e633810f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_004a854e4a2a445496e2ed825140f887",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 731/? [06:09&lt;00:00,  2.03it/s, acc=0.943, epoch=6, f1=0.845, loss=0.158]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49e6e3beacbd4d97b88b2fed3c5ff1a6"
          }
        },
        "95c946abcee844508abb6032dac75c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01dd7ddf0b0b4ed094e4ff9d0a033f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be23546d86194c64998150e4cd3f3fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7438c89d7a945e98743f034ede620a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "004a854e4a2a445496e2ed825140f887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49e6e3beacbd4d97b88b2fed3c5ff1a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1765533f7be34d10854e21328df7bf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fa3557cbc6b407986f400d64a45f640",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab8c7181b65a4d3aa6df8bf5c5d1d133",
              "IPY_MODEL_1ae3bfeb72ee40e0a864cd470cc487c8",
              "IPY_MODEL_7f037055819f4ae5bd6f234c28c50f3e"
            ]
          }
        },
        "4fa3557cbc6b407986f400d64a45f640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab8c7181b65a4d3aa6df8bf5c5d1d133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2951b09df75c4aad8451bf4d861d05bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "split=eval: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6e03b7d9176495b93bc9a2d57f7beb5"
          }
        },
        "1ae3bfeb72ee40e0a864cd470cc487c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6fc6c5e891f435eb898dd025e25d33f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 40,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b20428dd1874b8a8ca97469fe63bfba"
          }
        },
        "7f037055819f4ae5bd6f234c28c50f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c90f0f56bf4480184f064e0581bb8c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40/40 [00:07&lt;00:00,  5.84it/s, acc=0.909, epoch=6, f1=0.74, loss=0.28]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1bd1cc76ade47ce8432a619879ce3d3"
          }
        },
        "2951b09df75c4aad8451bf4d861d05bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6e03b7d9176495b93bc9a2d57f7beb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6fc6c5e891f435eb898dd025e25d33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b20428dd1874b8a8ca97469fe63bfba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c90f0f56bf4480184f064e0581bb8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1bd1cc76ade47ce8432a619879ce3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0973da1ce2cf44868a934e7d3d1387f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b5a843573064e959421c9a660c28c71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1b408ba176864d3bacaf4614ed5338f3",
              "IPY_MODEL_6091f409a9ad43c7b519807cb9dbfb9c",
              "IPY_MODEL_10321b544e724447932a8a2b3b124889"
            ]
          }
        },
        "4b5a843573064e959421c9a660c28c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b408ba176864d3bacaf4614ed5338f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_643e9341ce474bc195bdfa2793dfa6b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f9bc4f2f85943c5ae21202031a0d3c4"
          }
        },
        "6091f409a9ad43c7b519807cb9dbfb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75207909486e418daea3070d93930adb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_868f174bbe924f41a30fe308ada3b964"
          }
        },
        "10321b544e724447932a8a2b3b124889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c7421664d95b449988969b951b3ded45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:04&lt;00:00,  2.01s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9bfe733de7940f4b5dc4f5226e28b7b"
          }
        },
        "643e9341ce474bc195bdfa2793dfa6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f9bc4f2f85943c5ae21202031a0d3c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75207909486e418daea3070d93930adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "868f174bbe924f41a30fe308ada3b964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7421664d95b449988969b951b3ded45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9bfe733de7940f4b5dc4f5226e28b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98b87a67743f454081dc4948e3ca5b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17b75628582a482dae3b43b77f03142c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a1277097c5c84d75b63bd5a3fba5f35d",
              "IPY_MODEL_eb1a79e723c84d4ab045ab75d4317bf1",
              "IPY_MODEL_4849d48eb53d4cf2a8360013b8dd3962"
            ]
          }
        },
        "17b75628582a482dae3b43b77f03142c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1277097c5c84d75b63bd5a3fba5f35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f359e2ad7e6a4ef9b95252abb31bb27d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "evaluation progress: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_320f5118b1de4146a9935180b6dc109c"
          }
        },
        "eb1a79e723c84d4ab045ab75d4317bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_13b1a23aa1c2490a8cbae7cebce44c51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1631c236cf4b4eeab37e118504a8e433"
          }
        },
        "4849d48eb53d4cf2a8360013b8dd3962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_687dee5c324f42e0abb9c98b197d314f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:01&lt;00:00,  8.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2bd06e1a76c4b3ca73463c2f2998736"
          }
        },
        "f359e2ad7e6a4ef9b95252abb31bb27d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "320f5118b1de4146a9935180b6dc109c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13b1a23aa1c2490a8cbae7cebce44c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1631c236cf4b4eeab37e118504a8e433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "687dee5c324f42e0abb9c98b197d314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2bd06e1a76c4b3ca73463c2f2998736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eea7b43de2af441099a2386cb9402102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93eb43ce3190449d97b32d0ab1370ac9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a233c77c42fb4875a499a81aa16f1b08",
              "IPY_MODEL_c17e8d9d3c634892aab6644ba8dbd4d7",
              "IPY_MODEL_fa629b73ec2b4e16b54fad41d30b2c33"
            ]
          }
        },
        "93eb43ce3190449d97b32d0ab1370ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a233c77c42fb4875a499a81aa16f1b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e4623e6896549a8a5f3818ec604a5d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "evaluation progress: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60ba54a3b3544a94b0703f3754aa1c5c"
          }
        },
        "c17e8d9d3c634892aab6644ba8dbd4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d7abd4543b74abbb2a5e905a38cffff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7b72eefd50d4894bb7ec57d060540f6"
          }
        },
        "fa629b73ec2b4e16b54fad41d30b2c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0e073f35b684fd38f1c47db9f93d188",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:01&lt;00:00,  8.36it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb228a50e80f4a4d941c6c1cd7a25214"
          }
        },
        "8e4623e6896549a8a5f3818ec604a5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60ba54a3b3544a94b0703f3754aa1c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d7abd4543b74abbb2a5e905a38cffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7b72eefd50d4894bb7ec57d060540f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0e073f35b684fd38f1c47db9f93d188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb228a50e80f4a4d941c6c1cd7a25214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_dUF2evouow"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cozek/OffensEval2020-code/blob/master/notebooks/Eng%20Task%20C%20-%20Ensemble%20DistilRoberta%20AttnMask%20Dropout.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Uo50Chouox"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "At the time of our work, we used the following library versions\n",
        "- numpy 1.18.1\n",
        "- pandas 1.0.1\n",
        "- torch 1.2.0\n",
        "- Cuda 10.0\n",
        "- python 3.7.0\n",
        "- sklearn 0.22.1\n",
        "- tqdm 4.42.1\n",
        "- nltk 3.4.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFPGTXG3ouox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "126c72d8-e1eb-40db-b3f3-6738397868e9"
      },
      "source": [
        "!git clone https://github.com/KennethSunn/Intro-to-NLP-Final-Project-Fall2021.git"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Intro-to-NLP-Final-Project-Fall2021'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 78 (delta 23), reused 37 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpGHYSkhouo0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "outputId": "6a8fc035-e2cc-40fd-c538-73829ab7d0f5"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformershttps://github.com/KennethSunn/Intro-to-NLP-Final-Project-Fall2021.git\n",
        "!pip install /content/transformers/"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Intro-to-NLP-Final-Project-Fall2021' already exists and is not an empty directory.\n",
            "Processing ./transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (0.0.46)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (0.2.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.14.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.14.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.14.0.dev0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.14.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.14.0.dev0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.14.0.dev0) (7.1.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.14.0.dev0-py3-none-any.whl size=3320842 sha256=003c2bfec5977d6e9788de55fa6a09848395f7967afa313770a28f42d7f219e4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q9ccj8hp/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.14.0.dev0\n",
            "    Uninstalling transformers-4.14.0.dev0:\n",
            "      Successfully uninstalled transformers-4.14.0.dev0\n",
            "Successfully installed transformers-4.14.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6om7VnoNouo3"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/OffensEval2020-code/src/')\n",
        "import collections\n",
        "from typing import Callable\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "from tqdm import notebook\n",
        "import importlib\n",
        "import pprint\n",
        "import nltk\n",
        "import datetime\n",
        "import os\n",
        "from argparse import Namespace\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyUPjzykouo5"
      },
      "source": [
        "import utils.general as general_utils\n",
        "import utils.transformer.data as transformer_data_utils\n",
        "import utils.transformer.general as transformer_general_utils\n",
        "general_utils.set_seed_everywhere()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoJmxSDPouo9"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ehv7SLoouo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "53bc22e8-66a6-4257-b9fd-aa8199087fb1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.__version__ # we used version 1.2.0\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkS9WQy2oupC"
      },
      "source": [
        "# Import RAdam and Lookahead\n",
        "from radam.radam import RAdam\n",
        "from lookahead.optimizer import Lookahead\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71wul4V7oupF"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification, AlbertTokenizer, AlbertModel, AlbertForSequenceClassification"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoAlBoFYoupH"
      },
      "source": [
        " args = Namespace(\n",
        "        #use cuda by default\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \n",
        "        #set batch size and number of epochs\n",
        "        batch_size = 32,\n",
        "        num_epochs = 20,\n",
        "    \n",
        "        #set the learning rate\n",
        "        learning_rate = 0.0001,\n",
        "\n",
        "        #location of the train, dev and test csv\n",
        "        train_val_csv = '/content/OffensEval2020-code/data/eng/task_c_tiny.zip',\n",
        "        test_csv = '/content/OffensEval2020-code/data/test_data/test_a_tweets.tsv',\n",
        "    \n",
        "        #directory to save our models at\n",
        "        directory = './models/', \n",
        "        model_name = 'roberta_attn_trac_task_a.pt',\n",
        "     \n",
        "        date = datetime.datetime.now().strftime(\"%a_%d_%b_%Y/\"),\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt5X-gWsoupL"
      },
      "source": [
        "## Model save location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMOYDefpoupM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a57e658-6527-46ee-bef1-046a1e4600dd"
      },
      "source": [
        "directory = args.directory + args.date\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "args.directory = directory\n",
        "print(args.directory)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./models/Mon_13_Dec_2021/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thSqAbT3oupP"
      },
      "source": [
        "## Load presplit dataset portion\n",
        "```\n",
        "Labelled as\n",
        "\n",
        "IND = 0\n",
        "GRP = 1\n",
        "OTH = 2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WazWg4zoupP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "460b5905-369f-400b-d6bc-4eebb08d1334"
      },
      "source": [
        "data_df_task_c = pd.read_csv(args.train_val_csv, compression='zip')\n",
        "print(data_df_task_c.label.value_counts())\n",
        "print(data_df_task_c.split.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    45769\n",
            "1     7475\n",
            "2     3448\n",
            "Name: label, dtype: int64\n",
            "train    51165\n",
            "val       2834\n",
            "test      2693\n",
            "Name: split, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df_task_c.to_csv('/content/Task_c.csv')"
      ],
      "metadata": {
        "id": "4izOBK3rAgpb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k=data_df_task_c.iloc[51165:53999,:]\n",
        "test_set.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSNS4__4YSI",
        "outputId": "968ce369-a35c-4aca-f47b-49351195f08f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    580\n",
              "1    190\n",
              "2     80\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "C3zOC3CRovgr",
        "outputId": "585149f5-4ede-4160-a6d7-780288a6d177"
      },
      "source": [
        "test_set=pd.read_csv('test_c.csv')\n",
        "\n",
        "label_to_int = {'IND': 0, 'GRP':1,'OTH':2}\n",
        "\n",
        "test_set = test_set.replace({\"label\": label_to_int})\n",
        "test_set"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BC0</td>\n",
              "      <td>@USER Lmao bihhh dis what u do to your homies ...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BC3</td>\n",
              "      <td>@USER The POTUS is a racist, racist, racist, r...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BC9</td>\n",
              "      <td>@USER He then grinned, raising his brow.  Oh d...</td>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BC10</td>\n",
              "      <td>Niggas priorities be fucked all the way up</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BC19</td>\n",
              "      <td>You bitches really be walking around talking s...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>BC1903</td>\n",
              "      <td>Caught that fool Mario Lemos sucking dick behi...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>BC1906</td>\n",
              "      <td>@USER Ag,u a not going to say anything just li...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>BC1913</td>\n",
              "      <td>@USER 😂😂she always trynna be on my ass</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>BC1919</td>\n",
              "      <td>@USER F u all the way to hell. You are absolut...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>BC1921</td>\n",
              "      <td>@USER our club is becoming a joke, they can fu...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text  label split\n",
              "0       BC0  @USER Lmao bihhh dis what u do to your homies ...      0  test\n",
              "1       BC3  @USER The POTUS is a racist, racist, racist, r...      0  test\n",
              "2       BC9  @USER He then grinned, raising his brow.  Oh d...      2  test\n",
              "3      BC10         Niggas priorities be fucked all the way up      1  test\n",
              "4      BC19  You bitches really be walking around talking s...      1  test\n",
              "..      ...                                                ...    ...   ...\n",
              "845  BC1903  Caught that fool Mario Lemos sucking dick behi...      0  test\n",
              "846  BC1906  @USER Ag,u a not going to say anything just li...      0  test\n",
              "847  BC1913             @USER 😂😂she always trynna be on my ass      0  test\n",
              "848  BC1919  @USER F u all the way to hell. You are absolut...      0  test\n",
              "849  BC1921  @USER our club is becoming a joke, they can fu...      0  test\n",
              "\n",
              "[850 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZrYLTrxoupU"
      },
      "source": [
        "## Importing the Roberta Tokeniker and Punkt sentence tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtFADHnToupV"
      },
      "source": [
        "class RobertaPreprocessor():\n",
        "    def __init__(self,transformer_tokenizer,sentence_detector):\n",
        "        self.transformer_tokenizer = transformer_tokenizer\n",
        "        self.sentence_detector = sentence_detector\n",
        "        self.bos_token = transformer_tokenizer.bos_token\n",
        "        self.sep_token = ' ' + transformer_tokenizer.sep_token + ' '\n",
        "    def add_special_tokens(self, text):\n",
        "        sentences = self.sentence_detector.tokenize(text)\n",
        "        eos_added_text  = self.sep_token.join(sentences) \n",
        "        return self.bos_token +' '+ eos_added_text + ' ' + self.transformer_tokenizer.sep_token\n",
        "!python -c 'import nltk; nltk.download(\"punkt\")'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6RlaXDBtoupY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "547b3b1e7242417aa69b8b9f7816cfef",
            "264a7a8cfef84eaf8ded6de572dfe903",
            "ac69e9fe1d9d422ca4f11bca8ecd1e0c",
            "afc2c2874e5f4f0b8cf2a4cdfcc900bf",
            "c2462834827c429394d4b8f6269673d0",
            "df5185c75df041b6be13e77b8e44b912",
            "0c5b4bb4db32482f9940f8e486d081f6",
            "6591e11f069a4f9fa409cd11a1e68804",
            "50d14a915b544bd595e256f1bdb33b27",
            "a4a2cd2770004e048a991f0c80ef15c0",
            "2d035b5186b34aed8b7b3de6d6e465a2",
            "9dde202facd44e15a11e960a1e72986d",
            "dc41d8933fe248e293ea974366f368b1",
            "3d70f421be0f4cf18520c883c3e391df",
            "32fc3c792bf44b7599e72158dff780ea",
            "b21e2c92a37f494fa3fae15edb0b19c1",
            "fecb2cb53635447bb053d4baf166549c",
            "4b6f3c54149a476e9c66457b6efe5725",
            "5a23f7f1c0e64b2799975ffeb06ca0f5",
            "c73f05ab90974b499082298251060e43",
            "3cc94df9ce894c21b581e8bdbd14f6f9",
            "3e89e1794e8a4a50acaf71c746c49e3c",
            "9ef4cf827b98463f8b90a5da4f370536",
            "0d2a3a8cbb394904a97bd8105214df6c",
            "5f4d34caf198402b9df9408631c8b112",
            "a6de4b7709d3482780e1529b66034b9b",
            "65d76e52afec473d830ec5222f247fc3",
            "761fff9acfb54e52811dd0bd3f9812f2",
            "d3461e00be764f70b0115eb3d8ac5832",
            "a1ce5710a96c4b1b84580bb7a624ce8b",
            "76e3a77fcbc14070a6f9d7ba075fb69e",
            "37bf26f18078422fa49994d00a8ed292",
            "6c5ee266fb9b4f22a75436f3d949bb5b",
            "24a041d4024d4661807592836a776f7e",
            "0177a608bb834d9aa81e354f822bc1b7",
            "3ab517d94bca4418aca8707b81c8fc3b",
            "07aeda16928e4ac9a62af79a3a9e5927",
            "872c2ae583584eea9e5c6fe74623cf04",
            "c5a2412342da41c4aa749fca49a7e924",
            "274a625e202f4a48b9756c9f2c86fb6a",
            "8845c1ca776d475c88b44cb75814191e",
            "208b28f930e94cfb8176d0271c59c722",
            "514e7d7518a440148756605cb44e28f2",
            "10625350badf47e8a0187ebaf95a34a0"
          ]
        },
        "outputId": "b6b6f449-401f-4d24-af81-da799b0516d4"
      },
      "source": [
        "roberta_tokenizer =  tokenizer= RobertaTokenizer.from_pretrained('distilroberta-base')\n",
        "punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "547b3b1e7242417aa69b8b9f7816cfef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9dde202facd44e15a11e960a1e72986d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ef4cf827b98463f8b90a5da4f370536",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24a041d4024d4661807592836a776f7e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKFM-0bqoupb"
      },
      "source": [
        "roberta_preproc = RobertaPreprocessor(roberta_tokenizer, punkt_sentence_detector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDq61UIRoupf"
      },
      "source": [
        "#apply the preprocessor on the exploded dataframe\n",
        "data_df_task_c['text'] = data_df_task_c['text'].map(roberta_preproc.add_special_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTuondZBtPdt"
      },
      "source": [
        "#apply the preprocessor on the exploded dataframe\n",
        "test_set['text'] = test_set['text'].map(roberta_preproc.add_special_tokens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeHylINvTj54"
      },
      "source": [
        "class SimpleVectorizer():\n",
        "    def __init__(self,tokenizer: Callable, max_seq_len: int):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tokenizer (Callable): transformer tokenizer\n",
        "            max_seq_len (int): Maximum sequence lenght \n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self._max_seq_len = max_seq_len\n",
        "\n",
        "    def vectorize(self,text :str):\n",
        "        \n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=False, #already added by preproc\n",
        "            max_length = self._max_seq_len,\n",
        "            pad_to_max_length = True,\n",
        "        )\n",
        "        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n",
        "        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n",
        "        \n",
        "        return ids, attn\n",
        "\n",
        "class Vectorizer():\n",
        "    \"\"\"Vectorizer with Attention Mask Dropout\"\"\"\n",
        "    def __init__(self,tokenizer: Callable, max_seq_len: int ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tokenizer (Callable): transformer tokenizer\n",
        "            max_seq_len (int): Maximum sequence lenght \n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self._max_seq_len = max_seq_len\n",
        "\n",
        "    def vectorize(self,text :str, mask_prob: float = 0.50, mask_amount:float=0.30):\n",
        "        \"\"\"Implements Attention Mask Dropout\n",
        "        \n",
        "        Args:\n",
        "            text (str): The string to vectorize\n",
        "            mask_prob (float): Probability of the attention mask \n",
        "                dropout being applied\n",
        "            mask_amount (float): Percentage of tokens to mask\n",
        "\n",
        "        Returns:\n",
        "            ids (np.array)  : Array to token ids of the text\n",
        "            attn (np.array) : 0-1 Array of attention masks\n",
        "        \"\"\"\n",
        "\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=False, #already added by preproc\n",
        "            max_length = self._max_seq_len,\n",
        "            pad_to_max_length = True,\n",
        "        )\n",
        "        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n",
        "        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n",
        "        prob = np.random.rand(1)[0]\n",
        "        if  prob <= mask_prob:\n",
        "            len_of_sent = np.where(ids==tokenizer.pad_token_id)[0][0]\n",
        "            amount_to_mask = max(int(len_of_sent * mask_amount ) , 1)\n",
        "            ids_to_not_attend = [np.random.randint(low=0, high=len_of_sent )\n",
        "             for i in range(amount_to_mask)]\n",
        "            attn[ids_to_not_attend]=0\n",
        "            ids[ids_to_not_attend] = tokenizer.mask_token_id\n",
        "        return ids, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKPZAzQvTj55"
      },
      "source": [
        "Attention Mask Dropout Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9dyVVDkTj55"
      },
      "source": [
        "v = Vectorizer(roberta_tokenizer, 15) #attention maskdropout vectorizer\n",
        "sv = SimpleVectorizer(roberta_tokenizer, 15) #simple vectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34b72d3-050e-4115-f720-659eb62cb050",
        "id": "JiCkVY9PTj55"
      },
      "source": [
        "sent = \"I am alright bro, dont worry about me\"\n",
        "_, attn_masks_dropped = v.vectorize(sent)\n",
        "attn_masks_dropped"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce291a3-6974-4565-a610-e66bd7017e48",
        "id": "-308ElA3Tj55"
      },
      "source": [
        "_, attn_masks = sv.vectorize(sent)\n",
        "attn_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the ALBERT Tokeniker"
      ],
      "metadata": {
        "id": "0BNIxZHQXfxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class AlbertPreprocessor():\n",
        "    def __init__(self,transformer_tokenizer,sentence_detector):\n",
        "        self.transformer_tokenizer = transformer_tokenizer\n",
        "        self.sentence_detector = sentence_detector\n",
        "        self.bos_token = transformer_tokenizer.bos_token\n",
        "        self.sep_token = ' ' + transformer_tokenizer.sep_token + ' '\n",
        "    def add_special_tokens(self, text):\n",
        "        sentences = self.sentence_detector.tokenize(text)\n",
        "        eos_added_text  = self.sep_token.join(sentences) \n",
        "        return self.bos_token +' '+ eos_added_text + ' ' + self.transformer_tokenizer.sep_token\n",
        "\n",
        "!python -c 'import nltk; nltk.download(\"punkt\")'\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# % pip install sentencepiece\n",
        "\n",
        "albert_tokenizer =tokenizer= AlbertTokenizer.from_pretrained('albert-base-v1')\n",
        "punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "albert_preproc = AlbertPreprocessor(albert_tokenizer, punkt_sentence_detector)\n",
        "\n",
        "#apply the preprocessor on the exploded dataframe\n",
        "data_df_task_c['text'] = data_df_task_c['text'].map(albert_preproc.add_special_tokens)\n",
        "\n",
        "#apply the preprocessor on the exploded dataframe\n",
        "test_set['text'] = test_set['text'].map(albert_preproc.add_special_tokens)\n",
        "'''"
      ],
      "metadata": {
        "id": "RJhLMg5sXfJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKK3i-e9Tj55"
      },
      "source": [
        "###  Create the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYYXEVE-Tj55"
      },
      "source": [
        "class HateDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_df: pd.DataFrame,\n",
        "        tokenizer: Callable,\n",
        "        max_seq_length:int = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_df (pandas.DataFrame): df containing the labels and text\n",
        "            tokenizer (tokenizer module for the transformer)\n",
        "        \"\"\"\n",
        "        self.data_df = data_df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if max_seq_length is None:\n",
        "            self._max_seq_length = self._get_max_len(data_df,tokenizer)\n",
        "        else:\n",
        "            self._max_seq_length = max_seq_length\n",
        "\n",
        "        self.train_df = self.data_df[self.data_df.split == 'train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.data_df[self.data_df.split == 'val']\n",
        "        self.val_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.data_df[self.data_df.split == 'test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        \n",
        "        self.simple_vectorize = False,\n",
        "        self._simple_vectorizer = SimpleVectorizer(tokenizer, self._max_seq_length)\n",
        "        self._vectorizer = Vectorizer(tokenizer, self._max_seq_length)\n",
        "        \n",
        "        self._lookup_dict = {\n",
        "            'train': (self.train_df, self.train_size),\n",
        "            'val': (self.val_df, self.val_size),\n",
        "            'test': (self.test_df, self.test_size)\n",
        "        }\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "        class_counts = data_df.label.value_counts().to_dict()\n",
        "         #sorted on the basis of class label,eg, 0,1,2..\n",
        "        cts = sorted([(lbl,cts) for lbl,cts in class_counts.items()], key=lambda x: x[0])\n",
        "        freq = [ x[1] for x in cts ]\n",
        "        # print(freq,cts)\n",
        "        self.class_weights = 1.0/ torch.tensor(freq, dtype=torch.float32)\n",
        "    \n",
        "    def flip_simple_vectorizer(self) :\n",
        "        if self.simple_vectorize:\n",
        "            self.simple_vectorize=False\n",
        "        else:\n",
        "            self.simple_vectorize= True\n",
        "    \n",
        "    def _get_max_len(self,data_df: pd.DataFrame, tokenizer: Callable):\n",
        "        len_func = lambda x: len(self.tokenizer.encode_plus(x)['input_ids'])\n",
        "        max_len = data_df.text.map(len_func).max() \n",
        "        return max_len\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        if self._target_split == 'train':\n",
        "            indices, attention_masks = self._vectorizer.vectorize(row.text)\n",
        "        else:\n",
        "            indices, attention_masks = self._simple_vectorizer.vectorize(row.text)\n",
        "\n",
        "        label = row.label\n",
        "        return {'x_data': indices,\n",
        "                'x_attn_mask': attention_masks,\n",
        "                'x_index': index,\n",
        "                'y_target': label}\n",
        "    \n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnDLZxdsTj55"
      },
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last,\n",
        "                            pin_memory= pinned_memory,\n",
        "                            num_workers = n_workers,\n",
        "                            )\n",
        "    \n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        out_data_dict['x_data'] = data_dict['x_data'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_attn_mask'] = data_dict['x_attn_mask'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_index'] = data_dict['x_index']\n",
        "        out_data_dict['y_target'] = data_dict['y_target'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        yield out_data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOjCdORTj55"
      },
      "source": [
        "dataset = HateDataset(\n",
        "    data_df = data_df_task_c,\n",
        "    tokenizer = albert_tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkKy2al-Tj55"
      },
      "source": [
        "test_dataset = HateDataset(\n",
        "    data_df = test_set,\n",
        "    tokenizer = albert_tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TbUerp_ATj55"
      },
      "source": [
        "assert dataset._max_seq_length <= 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NOwcyecoupm"
      },
      "source": [
        "### Implement Attention Mask Dropout in the DistilRoBERTa   vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyQMayxOoupn"
      },
      "source": [
        "class SimpleVectorizer():\n",
        "    def __init__(self,tokenizer: Callable, max_seq_len: int):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tokenizer (Callable): transformer tokenizer\n",
        "            max_seq_len (int): Maximum sequence lenght \n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self._max_seq_len = max_seq_len\n",
        "\n",
        "    def vectorize(self,text :str):\n",
        "        \n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=False, #already added by preproc\n",
        "            max_length = self._max_seq_len,\n",
        "            pad_to_max_length = True,\n",
        "        )\n",
        "        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n",
        "        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n",
        "        \n",
        "        return ids, attn\n",
        "\n",
        "class Vectorizer():\n",
        "    \"\"\"Vectorizer with Attention Mask Dropout\"\"\"\n",
        "    def __init__(self,tokenizer: Callable, max_seq_len: int ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tokenizer (Callable): transformer tokenizer\n",
        "            max_seq_len (int): Maximum sequence lenght \n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self._max_seq_len = max_seq_len\n",
        "\n",
        "    def vectorize(self,text :str, mask_prob: float = 0.50, mask_amount:float=0.30):\n",
        "        \"\"\"Implements Attention Mask Dropout\n",
        "        \n",
        "        Args:\n",
        "            text (str): The string to vectorize\n",
        "            mask_prob (float): Probability of the attention mask \n",
        "                dropout being applied\n",
        "            mask_amount (float): Percentage of tokens to mask\n",
        "\n",
        "        Returns:\n",
        "            ids (np.array)  : Array to token ids of the text\n",
        "            attn (np.array) : 0-1 Array of attention masks\n",
        "        \"\"\"\n",
        "\n",
        "        encoded = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=False, #already added by preproc\n",
        "            max_length = self._max_seq_len,\n",
        "            pad_to_max_length = True,\n",
        "        )\n",
        "        ids =  np.array(encoded['input_ids'], dtype=np.int64)\n",
        "        attn = np.array(encoded['attention_mask'], dtype=np.int64)\n",
        "        prob = np.random.rand(1)[0]\n",
        "        if  prob <= mask_prob:\n",
        "            len_of_sent = np.where(ids==tokenizer.pad_token_id)[0][0]\n",
        "            amount_to_mask = max(int(len_of_sent * mask_amount ) , 1)\n",
        "            ids_to_not_attend = [np.random.randint(low=0, high=len_of_sent )\n",
        "             for i in range(amount_to_mask)]\n",
        "            attn[ids_to_not_attend]=0\n",
        "            ids[ids_to_not_attend] = tokenizer.mask_token_id\n",
        "        return ids, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0pI_W73rkHt"
      },
      "source": [
        "Attention Mask Dropout Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZTtbNz7oupp"
      },
      "source": [
        "v = Vectorizer(roberta_tokenizer, 15) #attention maskdropout vectorizer\n",
        "sv = SimpleVectorizer(roberta_tokenizer, 15) #simple vectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx4WAmFuoups",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c39a9d-df34-4004-8fca-23fd0e08ac2c"
      },
      "source": [
        "sent = \"I am alright bro, dont worry about me\"\n",
        "_, attn_masks_dropped = v.vectorize(sent)\n",
        "attn_masks_dropped"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGb2aQcTrWxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b910d2ab-b7a6-4c70-f15c-2734449ba0a1"
      },
      "source": [
        "_, attn_masks = sv.vectorize(sent)\n",
        "attn_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Attention Mask Dropout in the ALBERT vectorizer"
      ],
      "metadata": {
        "id": "1rnmtXP9VcgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "v = Vectorizer(albert_tokenizer, 15) #attention maskdropout vectorizer\n",
        "sv = SimpleVectorizer(albert_tokenizer, 15) #simple vectorizer\n",
        "\n",
        "sent = \"I am alright bro, dont worry about me\"\n",
        "_, attn_masks_dropped = v.vectorize(sent)\n",
        "attn_masks_dropped\n",
        "\n",
        "_, attn_masks = sv.vectorize(sent)\n",
        "attn_masks\n",
        "\n",
        "\"\"\"###  Create the dataset class\"\"\"\n",
        "'''"
      ],
      "metadata": {
        "id": "_ZUpKXPTViAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfXDJER9wnGn"
      },
      "source": [
        "###  Create the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI0SzK1Woupw"
      },
      "source": [
        "class HateDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_df: pd.DataFrame,\n",
        "        tokenizer: Callable,\n",
        "        max_seq_length:int = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_df (pandas.DataFrame): df containing the labels and text\n",
        "            tokenizer (tokenizer module for the transformer)\n",
        "        \"\"\"\n",
        "        self.data_df = data_df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if max_seq_length is None:\n",
        "            self._max_seq_length = self._get_max_len(data_df,tokenizer)\n",
        "        else:\n",
        "            self._max_seq_length = max_seq_length\n",
        "\n",
        "        self.train_df = self.data_df[self.data_df.split == 'train']\n",
        "        self.train_size = len(self.train_df)\n",
        "\n",
        "        self.val_df = self.data_df[self.data_df.split == 'val']\n",
        "        self.val_size = len(self.val_df)\n",
        "\n",
        "        self.test_df = self.data_df[self.data_df.split == 'test']\n",
        "        self.test_size = len(self.test_df)\n",
        "        \n",
        "        self.simple_vectorize = False,\n",
        "        self._simple_vectorizer = SimpleVectorizer(tokenizer, self._max_seq_length)\n",
        "        self._vectorizer = Vectorizer(tokenizer, self._max_seq_length)\n",
        "        \n",
        "        self._lookup_dict = {\n",
        "            'train': (self.train_df, self.train_size),\n",
        "            'val': (self.val_df, self.val_size),\n",
        "            'test': (self.test_df, self.test_size)\n",
        "        }\n",
        "\n",
        "        self.set_split('train')\n",
        "\n",
        "        class_counts = data_df.label.value_counts().to_dict()\n",
        "         #sorted on the basis of class label,eg, 0,1,2..\n",
        "        cts = sorted([(lbl,cts) for lbl,cts in class_counts.items()], key=lambda x: x[0])\n",
        "        freq = [ x[1] for x in cts ]\n",
        "        # print(freq,cts)\n",
        "        self.class_weights = 1.0/ torch.tensor(freq, dtype=torch.float32)\n",
        "    \n",
        "    def flip_simple_vectorizer(self) :\n",
        "        if self.simple_vectorize:\n",
        "            self.simple_vectorize=False\n",
        "        else:\n",
        "            self.simple_vectorize= True\n",
        "    \n",
        "    def _get_max_len(self,data_df: pd.DataFrame, tokenizer: Callable):\n",
        "        len_func = lambda x: len(self.tokenizer.encode_plus(x)['input_ids'])\n",
        "        max_len = data_df.text.map(len_func).max() \n",
        "        return max_len\n",
        "\n",
        "    def set_split(self, split=\"train\"):\n",
        "        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n",
        "        self._target_split = split\n",
        "        self._target_df, self._target_size = self._lookup_dict[split]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self._target_size\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"the primary entry point method for PyTorch datasets\n",
        "        \n",
        "        Args:\n",
        "            index (int): the index to the data point \n",
        "        Returns:\n",
        "            a dictionary holding the data point's features (x_data) and label (y_target)\n",
        "        \"\"\"\n",
        "        row = self._target_df.iloc[index]\n",
        "        \n",
        "        if self._target_split == 'train':\n",
        "            indices, attention_masks = self._vectorizer.vectorize(row.text)\n",
        "        else:\n",
        "            indices, attention_masks = self._simple_vectorizer.vectorize(row.text)\n",
        "\n",
        "        label = row.label\n",
        "        return {'x_data': indices,\n",
        "                'x_attn_mask': attention_masks,\n",
        "                'x_index': index,\n",
        "                'y_target': label}\n",
        "    \n",
        "    def get_num_batches(self, batch_size):\n",
        "        \"\"\"Given a batch size, return the number of batches in the dataset\n",
        "        \n",
        "        Args:\n",
        "            batch_size (int)\n",
        "        Returns:\n",
        "            number of batches in the dataset\n",
        "        \"\"\"\n",
        "        return len(self) // batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGvvsTq9oupy"
      },
      "source": [
        "def generate_batches(dataset, batch_size, shuffle=True,\n",
        "                     drop_last=False, device=\"cpu\", pinned_memory = False, n_workers = 0): \n",
        "    \"\"\"\n",
        "    A generator function which wraps the PyTorch DataLoader. It will \n",
        "      ensure each tensor is on the write device location.\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                            shuffle=shuffle, drop_last=drop_last,\n",
        "                            pin_memory= pinned_memory,\n",
        "                            num_workers = n_workers,\n",
        "                            )\n",
        "    \n",
        "    for data_dict in dataloader:\n",
        "        out_data_dict = {}\n",
        "        out_data_dict['x_data'] = data_dict['x_data'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_attn_mask'] = data_dict['x_attn_mask'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        out_data_dict['x_index'] = data_dict['x_index']\n",
        "        out_data_dict['y_target'] = data_dict['y_target'].to(\n",
        "            device, non_blocking= (True if pinned_memory else False) \n",
        "        )\n",
        "        yield out_data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqjxEQKZoup0"
      },
      "source": [
        "dataset = HateDataset(\n",
        "    data_df = data_df_task_c,\n",
        "    tokenizer = roberta_tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uaeecsx_t_Yv"
      },
      "source": [
        "test_dataset = HateDataset(\n",
        "    data_df = test_set,\n",
        "    tokenizer = roberta_tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "r1S0e8djoup3"
      },
      "source": [
        "assert dataset._max_seq_length <= 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faAM7TdDoup5"
      },
      "source": [
        "# Initialize the Roberta model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Sdjpj_fvoup6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "3402debb209a4eea99ca4a06ff83cfff",
            "0a6ee4d51a6b4eb5bd84bbb11efcd908",
            "e56b5d61e9494381967a0ae34f490247",
            "94bba555c3ec431ab65f3cfa1789cf9c",
            "7a0dd9dbe39d4f849cb411961c000c7c",
            "1611203a8d5c4ec29f14030c48d4fcca",
            "979f47c68abf4bf8a36fa685bfd8105f",
            "2b516eeaee74483893962c297e103886",
            "525dbeb604ad4cb8bd008c145482c20a",
            "f12a189174f74406ba581cb3e1b51649",
            "82d0d21d84bb457586849b3e90614280"
          ]
        },
        "outputId": "e0be7d9f-e215-4e10-8208-a6e5a0626516"
      },
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    'distilroberta-base',\n",
        "    num_labels=len(set(data_df_task_c.label)),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3402debb209a4eea99ca4a06ff83cfff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7VAugC07oup8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf2f307-8efc-4993-cc71-accd1294d85f"
      },
      "source": [
        "model.to(args.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nf9iX9Eoup_"
      },
      "source": [
        "early_stopping = transformer_general_utils.EarlyStopping(patience=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjtphpU6s4LV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc03c46e-793d-41bc-9226-0ef85ea4addf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  4 20:35:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    33W / 250W |   1471MiB / 16280MiB |     17%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjFXYTcEouqB"
      },
      "source": [
        "args.num_epochs = 20\n",
        "args.batch_size = 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "OYfdxscNouqE"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f'Using LR:{args.learning_rate}')\n",
        "base_optimizer = RAdam(model.parameters(), lr = args.learning_rate)\n",
        "optimizer = Lookahead(optimizer = base_optimizer, k = 5, alpha=0.5 )\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer.optimizer, factor =0.1 ,mode='max',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MckOvOKoV8O0"
      },
      "source": [
        "# Initialize the ALBERT model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "3402debb209a4eea99ca4a06ff83cfff",
            "0a6ee4d51a6b4eb5bd84bbb11efcd908",
            "e56b5d61e9494381967a0ae34f490247",
            "94bba555c3ec431ab65f3cfa1789cf9c",
            "7a0dd9dbe39d4f849cb411961c000c7c",
            "1611203a8d5c4ec29f14030c48d4fcca",
            "979f47c68abf4bf8a36fa685bfd8105f",
            "2b516eeaee74483893962c297e103886",
            "525dbeb604ad4cb8bd008c145482c20a",
            "f12a189174f74406ba581cb3e1b51649",
            "82d0d21d84bb457586849b3e90614280"
          ]
        },
        "outputId": "e0be7d9f-e215-4e10-8208-a6e5a0626516",
        "id": "aIqB8X2JV8O1"
      },
      "source": [
        "'''\n",
        "model = AlbertForSequenceClassification.from_pretrained(\n",
        "    'albert-base-v2',\n",
        "    num_labels=len(set(data_df_task_c.label)),\n",
        ")\n",
        "\n",
        "model.to(args.device)\n",
        "\n",
        "early_stopping = transformer_general_utils.EarlyStopping(patience=4)\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "args.num_epochs = 20\n",
        "args.batch_size = 70\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f'Using LR:{args.learning_rate}')\n",
        "base_optimizer = RAdam(model.parameters(), lr = args.learning_rate)\n",
        "optimizer = Lookahead(optimizer = base_optimizer, k = 5, alpha=0.5 )\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer.optimizer, factor =0.1 ,mode='max',\n",
        ")\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3402debb209a4eea99ca4a06ff83cfff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhB0DIPouqH"
      },
      "source": [
        "# Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "3402debb209a4eea99ca4a06ff83cfff",
            "0a6ee4d51a6b4eb5bd84bbb11efcd908",
            "e56b5d61e9494381967a0ae34f490247",
            "94bba555c3ec431ab65f3cfa1789cf9c",
            "7a0dd9dbe39d4f849cb411961c000c7c",
            "1611203a8d5c4ec29f14030c48d4fcca",
            "979f47c68abf4bf8a36fa685bfd8105f",
            "2b516eeaee74483893962c297e103886",
            "525dbeb604ad4cb8bd008c145482c20a",
            "f12a189174f74406ba581cb3e1b51649",
            "82d0d21d84bb457586849b3e90614280"
          ]
        },
        "outputId": "e0be7d9f-e215-4e10-8208-a6e5a0626516",
        "id": "RtYIa9raV5nC"
      },
      "source": [
        "model = AlbertForSequenceClassification.from_pretrained(\n",
        "    'distilroberta-base',\n",
        "    num_labels=len(set(data_df_task_c.label)),\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3402debb209a4eea99ca4a06ff83cfff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf2f307-8efc-4993-cc71-accd1294d85f",
        "id": "uPDwIJmPV5nC"
      },
      "source": [
        "model.to(args.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvu-RtzUV5nD"
      },
      "source": [
        "early_stopping = transformer_general_utils.EarlyStopping(patience=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc03c46e-793d-41bc-9226-0ef85ea4addf",
        "id": "i-4HnKSjV5nD"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  4 20:35:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    33W / 250W |   1471MiB / 16280MiB |     17%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp1twugTV5nD"
      },
      "source": [
        "args.num_epochs = 20\n",
        "args.batch_size = 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MItEf0x2V5nD"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f'Using LR:{args.learning_rate}')\n",
        "base_optimizer = RAdam(model.parameters(), lr = args.learning_rate)\n",
        "optimizer = Lookahead(optimizer = base_optimizer, k = 5, alpha=0.5 )\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer.optimizer, factor =0.1 ,mode='max',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta4xhZcdouqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0a0852-3b87-4a31-aea0-43173b694b13"
      },
      "source": [
        "train_state = general_utils.make_train_state()\n",
        "train_state.keys()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train_preds', 'train_indexes', 'train_targets', 'train_accuracies', 'train_f1s', 'train_losses', 'val_preds', 'val_indexes', 'val_targets', 'val_accuracies', 'val_f1s', 'val_losses', 'test_preds', 'test_indexes', 'test_targets', 'test_accuracies', 'test_f1s', 'test_losses', 'batch_preds', 'batch_targets', 'batch_indexes', 'epoch_index'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Hyp2Q5ReouqK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2152d09dfa41445c843a19707180c7f8",
            "63de84121fca4d859425fd852237212e",
            "d4abae12fb0947138e7b7ebd63dc52ff",
            "20fc314407724eca9138bdb88d2f156d",
            "4185483be77f4d23bf103aec4e25545b",
            "a0c727e9ba62439e9dc71c8e227ef759",
            "631df1a3c3754c2b8abe3b78f05c464a",
            "0f69cefb2c504ea4911004829402992f",
            "cc706ccbfcd042578282591828e74db7",
            "f870bccaa2ca47b097bc6c828a7fb35f",
            "66d73e1ef2824419980efa33a533adeb",
            "0cf8dfed34c245548f29cc436a280b49",
            "69d4a1164c0f4f4282fdb42aa7576d3a",
            "f94b725bbb5d48e0a9fca900e4cfaa6b",
            "018268f03cc6430389f3e36dc1286ce8",
            "c5ce6820c5014d1595dbd52e633810f9",
            "95c946abcee844508abb6032dac75c4e",
            "01dd7ddf0b0b4ed094e4ff9d0a033f0b",
            "be23546d86194c64998150e4cd3f3fd3",
            "a7438c89d7a945e98743f034ede620a8",
            "004a854e4a2a445496e2ed825140f887",
            "49e6e3beacbd4d97b88b2fed3c5ff1a6",
            "1765533f7be34d10854e21328df7bf8c",
            "4fa3557cbc6b407986f400d64a45f640",
            "ab8c7181b65a4d3aa6df8bf5c5d1d133",
            "1ae3bfeb72ee40e0a864cd470cc487c8",
            "7f037055819f4ae5bd6f234c28c50f3e",
            "2951b09df75c4aad8451bf4d861d05bf",
            "d6e03b7d9176495b93bc9a2d57f7beb5",
            "c6fc6c5e891f435eb898dd025e25d33f",
            "2b20428dd1874b8a8ca97469fe63bfba",
            "9c90f0f56bf4480184f064e0581bb8c7",
            "f1bd1cc76ade47ce8432a619879ce3d3"
          ]
        },
        "outputId": "a8b1a111-b216-444c-cf00-7e384cfca7d7"
      },
      "source": [
        "epoch_bar = notebook.tqdm(\n",
        "    desc = 'training_routine',\n",
        "    total = args.num_epochs,\n",
        "    position=0,\n",
        "    leave = True,\n",
        ")\n",
        "dataset.set_split('train')\n",
        "train_bar = notebook.tqdm(\n",
        "    desc = 'split=train ',\n",
        "    total=dataset.get_num_batches(args.batch_size),\n",
        "    position=0,\n",
        "    leave=True,\n",
        ")\n",
        "dataset.set_split('val')\n",
        "eval_bar = notebook.tqdm(\n",
        "    desc = 'split=eval',\n",
        "    total=dataset.get_num_batches(args.batch_size),\n",
        "    position=0,\n",
        "    leave=True,\n",
        ")\n",
        "\n",
        "old_val_acc = 0\n",
        "old_f1 = 0\n",
        "model_state = None\n",
        "for epoch_index in range(7):#args.num_epochs\n",
        "    train_state['epoch_in'] = epoch_index\n",
        "\n",
        "    dataset.set_split('train')\n",
        "\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = True, n_workers = 3, \n",
        "    )\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    running_f1 = 0.0\n",
        "    model.train()\n",
        "\n",
        "    train_bar.reset(\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "\n",
        "    for batch_index, batch_dict in enumerate(batch_generator):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss,y_pred = model(\n",
        "            input_ids = batch_dict['x_data'],\n",
        "            attention_mask =  batch_dict['x_attn_mask'],\n",
        "            labels= batch_dict['y_target'].unsqueeze(1),\n",
        "        )[:2]\n",
        "        \n",
        "        y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
        "                             \n",
        "#         scheduler.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                             \n",
        "        loss_t = loss.item()\n",
        "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "                             \n",
        "        y_pred = y_pred.detach().cpu()\n",
        "        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
        "        \n",
        "        acc_t = transformer_general_utils \\\n",
        "            .compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "        \n",
        "        f1_t = transformer_general_utils \\\n",
        "            .compute_macro_f1(y_pred, batch_dict['y_target'])\n",
        "\n",
        "        train_state['batch_preds'].append(y_pred)\n",
        "        train_state['batch_targets'].append(batch_dict['y_target'])\n",
        "        train_state['batch_indexes'].append(batch_dict['x_index'])\n",
        "\n",
        "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
        "\n",
        "        train_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
        "                             epoch=epoch_index)\n",
        "\n",
        "        train_bar.update()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    train_state['train_accuracies'].append(running_acc)\n",
        "    train_state['train_losses'].append(running_loss)\n",
        "    \n",
        "    train_state['train_preds'].append(\n",
        "        torch.cat(train_state['batch_preds']).cpu()\n",
        "    )\n",
        "    train_state['train_targets'].append(\n",
        "        torch.cat(train_state['batch_targets']).cpu()\n",
        "    )\n",
        "    train_state['train_indexes'].append(\n",
        "        torch.cat(train_state['batch_indexes']).cpu()\n",
        "    )\n",
        "    train_f1 = transformer_general_utils \\\n",
        "                .compute_macro_f1(train_state['train_preds'][-1],\n",
        "                                  train_state['train_targets'][-1],\n",
        "                                 )\n",
        "                                 \n",
        "    train_state['train_f1s'].append(train_f1)\n",
        "    \n",
        "    train_state['batch_preds'] = []\n",
        "    train_state['batch_targets'] = []\n",
        "    train_state['batch_indexes'] = []\n",
        "    \n",
        "    \n",
        "    dataset.set_split('val')\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = True, n_workers = 2, \n",
        "    )\n",
        "    eval_bar.reset(\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    running_f1 = 0.0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        optimizer._backup_and_load_cache()\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            loss, y_pred = model(\n",
        "                input_ids = batch_dict['x_data'],\n",
        "                attention_mask =  batch_dict['x_attn_mask'],\n",
        "                labels= batch_dict['y_target'].unsqueeze(1),\n",
        "            )[:2]\n",
        "            y_pred = y_pred.view(-1, len(set(dataset.data_df.label)))\n",
        "            \n",
        "            loss_t = loss.item()\n",
        "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
        "\n",
        "            y_pred = y_pred.detach()\n",
        "            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n",
        "            \n",
        "            acc_t = transformer_general_utils\\\n",
        "                .compute_accuracy(y_pred, batch_dict['y_target'])\n",
        "            f1_t = transformer_general_utils \\\n",
        "                .compute_macro_f1(y_pred, batch_dict['y_target'])\n",
        "\n",
        "            train_state['batch_preds'].append(y_pred.cpu())\n",
        "            train_state['batch_targets'].append(batch_dict['y_target'].cpu())\n",
        "            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
        "\n",
        "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
        "            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n",
        "            \n",
        "\n",
        "            eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n",
        "                                 epoch=epoch_index)\n",
        "            eval_bar.update()\n",
        "            \n",
        "    train_state['val_accuracies'].append(running_acc)\n",
        "    train_state['val_losses'].append(running_loss)\n",
        "    \n",
        "        \n",
        "    train_state['val_preds'].append(\n",
        "        torch.cat(train_state['batch_preds']).cpu()\n",
        "    )\n",
        "\n",
        "    train_state['val_targets'].append(\n",
        "        torch.cat(train_state['batch_targets']).cpu()\n",
        "    )\n",
        "    train_state['val_indexes'].append(\n",
        "        torch.cat(train_state['batch_indexes']).cpu()\n",
        "    )\n",
        "    val_f1 = transformer_general_utils \\\n",
        "                .compute_macro_f1(train_state['val_preds'][-1],\n",
        "                                  train_state['val_targets'][-1],\n",
        "                                 )\n",
        "                                 \n",
        "    train_state['val_f1s'].append(val_f1)\n",
        "    \n",
        "    train_state['batch_preds'] = []\n",
        "    train_state['batch_targets'] = []\n",
        "    train_state['batch_indexes'] = []\n",
        "    \n",
        "    torch.save(\n",
        "        {\n",
        "            'model':model.state_dict(),\n",
        "        },\n",
        "        args.directory + f'_epoc_{epoch_index}_' + args.model_name,\n",
        "    )\n",
        "    \n",
        "    scheduler.step(val_f1)\n",
        "    early_stopping(val_f1, model)\n",
        "    optimizer._clear_and_load_backup()\n",
        "    epoch_bar.set_postfix( best_f1 = early_stopping.best_score, current = val_f1)\n",
        "    epoch_bar.update()    \n",
        "    \n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2152d09dfa41445c843a19707180c7f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training_routine:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cf8dfed34c245548f29cc436a280b49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=train :   0%|          | 0/730 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1765533f7be34d10854e21328df7bf8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "split=eval:   0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/content/OffensEval2020-code/src/radam/radam.py:58: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 3 out of 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 4 out of 4\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvhJbjv3ouqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a03380-5ea4-4330-926c-6a5a71239bce"
      },
      "source": [
        "epoch_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UZ_tiTQsouqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8274c576-b5aa-4bd6-efb2-50d8679b060f"
      },
      "source": [
        "print(train_state['val_f1s'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7190917399957661, 0.7345660129162933, 0.7691962208764762, 0.7596123759482151, 0.7529665017277498, 0.7666879945094469, 0.7581459179742979]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGTvvqJOouqS"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmsdTS5XouqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01654885-8c75-423b-f9e7-095e6e6d703a"
      },
      "source": [
        "\n",
        "print('Train:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['train_preds'][-1],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['train_targets'][-1].cpu().numpy(), \n",
        "    digits=4)\n",
        ")\n",
        "print('Dev:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['val_preds'][-1],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['val_targets'][-1].cpu().numpy(), \n",
        "    digits=4)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9619    0.9769    0.9693     41307\n",
            "           1     0.8848    0.8435    0.8636      6746\n",
            "           2     0.7912    0.7076    0.7471      3112\n",
            "\n",
            "    accuracy                         0.9429     51165\n",
            "   macro avg     0.8793    0.8426    0.8600     51165\n",
            "weighted avg     0.9413    0.9429    0.9419     51165\n",
            "\n",
            "Dev:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9446    0.9611    0.9528      2288\n",
            "           1     0.7888    0.7888    0.7888       374\n",
            "           2     0.6136    0.4709    0.5329       172\n",
            "\n",
            "    accuracy                         0.9086      2834\n",
            "   macro avg     0.7823    0.7403    0.7581      2834\n",
            "weighted avg     0.9039    0.9086    0.9056      2834\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBvhO_3MouqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9252466-2596-45db-e730-09caff90a07a"
      },
      "source": [
        "best_run_index = train_state['val_f1s'].index(max(train_state['val_f1s']))\n",
        "print('Train:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['train_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['train_targets'][best_run_index].cpu().numpy(), \n",
        "    digits=4)\n",
        ")\n",
        "print('Dev:',classification_report(\n",
        "    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n",
        "    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n",
        "    digits=4)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9307    0.9659    0.9480     41307\n",
            "           1     0.7999    0.7425    0.7701      6746\n",
            "           2     0.6228    0.4075    0.4926      3112\n",
            "\n",
            "    accuracy                         0.9025     51165\n",
            "   macro avg     0.7845    0.7053    0.7369     51165\n",
            "weighted avg     0.8948    0.9025    0.8968     51165\n",
            "\n",
            "Dev:               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9513    0.9567    0.9540      2288\n",
            "           1     0.7664    0.8422    0.8025       374\n",
            "           2     0.6639    0.4709    0.5510       172\n",
            "\n",
            "    accuracy                         0.9121      2834\n",
            "   macro avg     0.7939    0.7566    0.7692      2834\n",
            "weighted avg     0.9095    0.9121    0.9096      2834\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyJlr1Ucouqa"
      },
      "source": [
        "def sort_preds(indexes, preds):\n",
        "    \"\"\"Sorts the predictions in order, to reverse the effects of shuffle\n",
        "    done by dataloader\"\"\"\n",
        "    indexes = indexes.cpu().numpy().reshape(-1,1)\n",
        "    preds = preds.cpu().numpy()\n",
        "    arr_concat = np.hstack((indexes,preds)) #concat the preds and their indexes\n",
        "    sort_arr = arr_concat[ arr_concat[:,0].argsort()] #sort based on the indexes\n",
        "    sorted_preds = np.delete(sort_arr,0,axis=1)\n",
        "    return sorted_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKLcktCourg"
      },
      "source": [
        "def get_optimal_models_v2(train_state, split):\n",
        "    l = zip(train_state[f'{split}_f1s'], range(len(train_state[f'{split}_f1s'])))\n",
        "    sorted_vals = sorted(l, key = lambda x:x[0], reverse=True)\n",
        "    model_idxes = [i[1] for i in sorted_vals]\n",
        "    \n",
        "    trgts= sort_preds(train_state[f'{split}_indexes'][-1],train_state[f'{split}_targets'][-1].reshape(-1,1))\n",
        "    total_preds = len(train_state[f'{split}_indexes'])\n",
        "    init = np.zeros(train_state[f'{split}_preds'][-1].shape)\n",
        "    max_f1 = 0\n",
        "    idxes = []\n",
        "    for i in model_idxes:\n",
        "        temp = sort_preds(train_state[f'{split}_indexes'][i],train_state[f'{split}_preds'][i])\n",
        "        temp2 = init+temp\n",
        "        f1 = f1_score(\n",
        "            y_pred=temp2.argmax(axis=1),\n",
        "            y_true= trgts, average ='macro'\n",
        "        )\n",
        "        if f1 > max_f1:\n",
        "            max_f1 = f1\n",
        "            init = init+temp\n",
        "            idxes.append(i)\n",
        "    print(f'Taking preds from {idxes} | Dev f1:{f1}')\n",
        "    return idxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RI0eIVAtourj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676d6910-3454-465c-83ee-b53b904549f1"
      },
      "source": [
        "final_optimal_models = get_optimal_models_v2(train_state, 'val')\n",
        "final_optimal_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taking preds from [2, 5] | Dev f1:0.7720562279258867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siZdY82mours"
      },
      "source": [
        "# Making preds on the given test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcztc0lGourz"
      },
      "source": [
        "test_df = test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRfZ2GLHousC"
      },
      "source": [
        "def evaluate_testset(model, state, dataset, split,args):\n",
        "    \"\"\"Returns the final layer output of our transformer model\n",
        "    Puts them in the '{split}_*' keys in the state dict\n",
        "    Args:\n",
        "        model: A pytorch transformers model\n",
        "        state: dict to store outputs\n",
        "        dataset: A pytorch Dataset\n",
        "        split: The split on which to evaluate the model on\n",
        "        args: Arguments from namespace, etc\n",
        "    Returns:\n",
        "        state: all evaluated output stored in the \"test\" key\n",
        "    \"\"\"\n",
        "    eval_bar = notebook.tqdm(\n",
        "        desc = 'evaluation progress: ',\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "        position=0,\n",
        "        leave=False,\n",
        "    )\n",
        "    dataset.set_split(split)\n",
        "    batch_generator = generate_batches(\n",
        "        dataset= dataset, batch_size= args.batch_size, shuffle=False,\n",
        "        device = args.device, drop_last=False,\n",
        "        pinned_memory = True, n_workers = 2, \n",
        "    )\n",
        "    eval_bar.reset(\n",
        "        total=dataset.get_num_batches(args.batch_size),\n",
        "    )\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_index, batch_dict in enumerate(batch_generator):\n",
        "            y_pred = model(\n",
        "                input_ids = batch_dict['x_data'],\n",
        "                attention_mask =  batch_dict['x_attn_mask'],\n",
        "            )[0]\n",
        "            y_pred = y_pred.view(-1, 3)\n",
        "\n",
        "            y_pred = y_pred.detach()\n",
        "            \n",
        "            state['batch_preds'].append(y_pred.cpu())\n",
        "            state['batch_indexes'].append(batch_dict['x_index'].cpu())\n",
        "            \n",
        "            eval_bar.update()\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    state[f'{split}_preds'].append(\n",
        "        torch.cat(state['batch_preds']).cpu()\n",
        "    )\n",
        "    state[f'{split}_indexes'].append(\n",
        "        torch.cat(state['batch_indexes']).cpu()\n",
        "    )\n",
        "    \n",
        "    state['batch_preds'] = []\n",
        "    state['batch_indexes'] = []\n",
        "    \n",
        "    eval_bar.close()\n",
        "    return state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXNCQ2jDwMiV",
        "outputId": "b594769f-e291-4a05-bba9-7bf917cf69fc"
      },
      "source": [
        "all_model_paths= [os.path.join(args.directory,i) for i in os.listdir(args.directory) if args.model_name in i]\n",
        "all_model_paths = sorted(all_model_paths, key = lambda x: int(x[31])) #sort by epoch num.\n",
        "all_model_paths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./models/Sat_04_Dec_2021/_epoc_0_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_1_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_2_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_3_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_4_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_5_roberta_attn_trac_task_a.pt',\n",
              " './models/Sat_04_Dec_2021/_epoc_6_roberta_attn_trac_task_a.pt']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDLAcVoOousD"
      },
      "source": [
        "chosen_models = [all_model_paths[i] for i in final_optimal_models]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43RKBZI7v5mm",
        "outputId": "ea2f1301-f273-4959-caf3-7437ce4ff86e"
      },
      "source": [
        "test_set['text'] = test_set['text'].map(roberta_preproc.add_special_tokens)\n",
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BC0</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER Lmao bihhh dis what u do to your...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BC3</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER The POTUS is a racist, racist, r...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BC9</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER He then grinned, raising his bro...</td>\n",
              "      <td>2</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BC10</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; Niggas priorities be fucked all the wa...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BC19</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; You bitches really be walking around t...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>BC1903</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; Caught that fool Mario Lemos sucking d...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>BC1906</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER Ag,u a not going to say anything...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>BC1913</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER 😂😂she always trynna be on my ass...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>BC1919</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER F u all the way to hell. &lt;/s&gt; &lt;/...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>BC1921</td>\n",
              "      <td>&lt;s&gt; &lt;s&gt; @USER our club is becoming a joke, the...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text  label split\n",
              "0       BC0  <s> <s> @USER Lmao bihhh dis what u do to your...      0  test\n",
              "1       BC3  <s> <s> @USER The POTUS is a racist, racist, r...      0  test\n",
              "2       BC9  <s> <s> @USER He then grinned, raising his bro...      2  test\n",
              "3      BC10  <s> <s> Niggas priorities be fucked all the wa...      1  test\n",
              "4      BC19  <s> <s> You bitches really be walking around t...      1  test\n",
              "..      ...                                                ...    ...   ...\n",
              "845  BC1903  <s> <s> Caught that fool Mario Lemos sucking d...      0  test\n",
              "846  BC1906  <s> <s> @USER Ag,u a not going to say anything...      0  test\n",
              "847  BC1913  <s> <s> @USER 😂😂she always trynna be on my ass...      0  test\n",
              "848  BC1919  <s> <s> @USER F u all the way to hell. </s> </...      0  test\n",
              "849  BC1921  <s> <s> @USER our club is becoming a joke, the...      0  test\n",
              "\n",
              "[850 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkeeEimUmnM8"
      },
      "source": [
        "test_dataset = HateDataset(\n",
        "    data_df = test_set,\n",
        "    tokenizer = roberta_tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRhTG0jJousG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "0973da1ce2cf44868a934e7d3d1387f5",
            "4b5a843573064e959421c9a660c28c71",
            "1b408ba176864d3bacaf4614ed5338f3",
            "6091f409a9ad43c7b519807cb9dbfb9c",
            "10321b544e724447932a8a2b3b124889",
            "643e9341ce474bc195bdfa2793dfa6b6",
            "0f9bc4f2f85943c5ae21202031a0d3c4",
            "75207909486e418daea3070d93930adb",
            "868f174bbe924f41a30fe308ada3b964",
            "c7421664d95b449988969b951b3ded45",
            "c9bfe733de7940f4b5dc4f5226e28b7b",
            "98b87a67743f454081dc4948e3ca5b23",
            "17b75628582a482dae3b43b77f03142c",
            "a1277097c5c84d75b63bd5a3fba5f35d",
            "eb1a79e723c84d4ab045ab75d4317bf1",
            "4849d48eb53d4cf2a8360013b8dd3962",
            "f359e2ad7e6a4ef9b95252abb31bb27d",
            "320f5118b1de4146a9935180b6dc109c",
            "13b1a23aa1c2490a8cbae7cebce44c51",
            "1631c236cf4b4eeab37e118504a8e433",
            "687dee5c324f42e0abb9c98b197d314f",
            "b2bd06e1a76c4b3ca73463c2f2998736",
            "eea7b43de2af441099a2386cb9402102",
            "93eb43ce3190449d97b32d0ab1370ac9",
            "a233c77c42fb4875a499a81aa16f1b08",
            "c17e8d9d3c634892aab6644ba8dbd4d7",
            "fa629b73ec2b4e16b54fad41d30b2c33",
            "8e4623e6896549a8a5f3818ec604a5d4",
            "60ba54a3b3544a94b0703f3754aa1c5c",
            "2d7abd4543b74abbb2a5e905a38cffff",
            "e7b72eefd50d4894bb7ec57d060540f6",
            "f0e073f35b684fd38f1c47db9f93d188",
            "bb228a50e80f4a4d941c6c1cd7a25214"
          ]
        },
        "outputId": "9cb5ba76-3003-49dc-da8e-2dd25d1e9af3"
      },
      "source": [
        "test_state = general_utils.make_train_state()\n",
        "for model_path in notebook.tqdm(chosen_models, total=len(chosen_models)):\n",
        "    model.load_state_dict(torch.load(model_path)['model'])\n",
        "    test_state = evaluate_testset(model, test_state, test_dataset, 'test',args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0973da1ce2cf44868a934e7d3d1387f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98b87a67743f454081dc4948e3ca5b23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "evaluation progress: : 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eea7b43de2af441099a2386cb9402102",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "evaluation progress:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyPLbSx_ousH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdabe49e-1ee6-4fd0-9b08-2d59d012c1ff"
      },
      "source": [
        "test_state['test_preds'][-1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([850, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9zIQn2PousJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cdacee-2b05-47de-b3f7-a4766d2ab713"
      },
      "source": [
        "[test_state['test_preds'][i].size() for i in range(len(test_state['test_preds']))]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([850, 3]), torch.Size([850, 3])]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-mAcbFFousO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74de4852-5d63-4a5e-8634-9c8300df143b"
      },
      "source": [
        "torch.zeros_like(test_state['test_preds'][0]).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([850, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw23sdIAousQ"
      },
      "source": [
        "ensemble_pred = torch.zeros_like(test_state['test_preds'][0])\n",
        "for i in test_state['test_preds']:\n",
        "    ensemble_pred += i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7l7scgnousU"
      },
      "source": [
        "int_to_label = { 0: 'IND', 1:'GRP', 2:'OTH'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIG3GtyDousW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27440dc0-c640-4baa-b254-2e9fdaf5af36"
      },
      "source": [
        "y_pred = []\n",
        "t = []\n",
        "for i in torch.argmax(ensemble_pred, dim=1):\n",
        "    y_pred.append(i)\n",
        "    t.append(int_to_label[i.item()])\n",
        "\n",
        "collections.Counter(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'GRP': 167, 'IND': 652, 'OTH': 31})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ppePXq5xc9j"
      },
      "source": [
        "y_true = np.array(test_set.iloc[:,2])\n",
        "test_acc = accuracy_score(y_pred, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgle7bgvyvBb",
        "outputId": "70e0f0c3-6da7-41bd-ec0d-6737040de5e4"
      },
      "source": [
        "test_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8094117647058824"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhalgslkzixB",
        "outputId": "494b9741-97e2-4763-a9b7-2864f5955b44"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred, y_true))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.89       652\n",
            "           1       0.63      0.71      0.67       167\n",
            "           2       0.28      0.71      0.40        31\n",
            "\n",
            "    accuracy                           0.81       850\n",
            "   macro avg       0.61      0.75      0.65       850\n",
            "weighted avg       0.86      0.81      0.83       850\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N43KI4P4ousY"
      },
      "source": [
        "assert len(t) == len(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANkfSvUSousa"
      },
      "source": [
        "offeval_task_c_pred_analysis_df = pd.DataFrame(\n",
        "    data={\n",
        "        'id':test_df.id,\n",
        "        'text':test_df.text,\n",
        "        'label':t,\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tYSn6VNousb"
      },
      "source": [
        "offeval_task_c_pred_label_df = pd.DataFrame(\n",
        "    data={\n",
        "        'id':test_df.id,\n",
        "        'label':t,\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ompoxc6Nousc"
      },
      "source": [
        "offeval_task_c_pred_analysis_df.to_csv(\n",
        "    'offeval_task_c_pred_analysis.csv',index=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHiGB2Q-ouse"
      },
      "source": [
        "offeval_task_c_pred_label_df.to_csv(\n",
        "    'offeval_task_c_pred_label.csv', index=False, header=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr707IBvousi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}